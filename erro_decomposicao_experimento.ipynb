{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experimento: Decomposição do Erro com Restrições Soft nos Coeficientes Polinomiais\n",
    "\n",
    "Este experimento simula a decomposição do erro (viés², variância e erro irredutível)\n",
    "de modelos polinomiais ajustados a dados sintéticos com ruído. A complexidade do modelo\n",
    "é controlada por um hiperparâmetro `alpha`, que define a penalização sobre os coeficientes\n",
    "do polinômio. Quanto menor o `alpha`, mais restritivos são os pesos de penalização, o que\n",
    "favorece modelos mais simples. O ajuste é feito por minimização de uma função de perda\n",
    "penalizada, sem restrições explícitas (penalização soft).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define a função verdadeira que gera os dados\n",
    "def f_true(x):\n",
    "    return 2 * x + np.cos(4 * np.pi * x)\n",
    "\n",
    "# Gera a base polinomial até um determinado grau\n",
    "def poly_basis(x, degree):\n",
    "    return np.vstack([x**k for k in range(degree + 1)]).T\n",
    "\n",
    "# -------------------------------\n",
    "# PARÂMETROS DO EXPERIMENTO\n",
    "# -------------------------------\n",
    "\n",
    "np.random.seed(42)           # Reprodutibilidade\n",
    "n_samples = 25               # Número de pontos de treino por dataset\n",
    "n_datasets = 100             # Número de datasets para simulação Monte Carlo\n",
    "n_test_points = 20           # Pontos de teste para avaliar o erro\n",
    "noise_std = 0.5              # Desvio padrão do ruído adicionado aos dados\n",
    "M = 1.0e3                    # Constante de escala da penalização\n",
    "degree = 71                  # Grau máximo do polinômio\n",
    "alpha_values = np.linspace(0.85, 1, 19)  # Valores de alpha (controlam complexidade)\n",
    "\n",
    "# -------------------------------\n",
    "# PREPARAÇÃO DOS PONTOS DE TESTE\n",
    "# -------------------------------\n",
    "\n",
    "x_test_points = np.random.rand(n_test_points)\n",
    "X_test = poly_basis(x_test_points, degree)\n",
    "f_real = f_true(x_test_points)\n",
    "\n",
    "# Inicializa listas para armazenar os erros\n",
    "bias2_list = []\n",
    "var_list = []\n",
    "noise_list = []\n",
    "\n",
    "# -------------------------------\n",
    "# LOOP SOBRE VALORES DE ALPHA\n",
    "# -------------------------------\n",
    "\n",
    "a_init = np.zeros(degree + 1)  # Inicialização comum para os coeficientes\n",
    "for cnt, alpha in enumerate(alpha_values, start=1):\n",
    "    preds = []  # Armazena predições em cada ponto para este alpha\n",
    "\n",
    "    # Penalidade crescente nos coeficientes: M * alpha^k\n",
    "    penalty_weights = M * np.array([alpha**k for k in range(degree + 1)])\n",
    "\n",
    "    print(f\"{cnt}/{len(alpha_values)} - α = {alpha:.4f}\")\n",
    "\n",
    "    for _ in range(n_datasets):\n",
    "        # Gera dados sintéticos com ruído\n",
    "        X_raw = np.linspace(0, 1, n_samples)\n",
    "        y = f_true(X_raw) + np.random.normal(0, noise_std, n_samples)\n",
    "        X_design = poly_basis(X_raw, degree)\n",
    "\n",
    "        # Define a função de perda penalizada (soft regularization)\n",
    "        def penalized_loss(a):\n",
    "            residual = np.mean((y - X_design @ a) ** 2)\n",
    "            penalty = np.sum((a / penalty_weights) ** 2)\n",
    "            return residual + penalty\n",
    "\n",
    "        # Minimiza a função de perda\n",
    "        res = minimize(penalized_loss, x0=a_init, method='L-BFGS-B')\n",
    "\n",
    "        # Atualiza os coeficientes ótimos\n",
    "        a_opt = res.x\n",
    "        a_init = a_opt  # Usar como ponto inicial da próxima iteração\n",
    "\n",
    "        # Realiza predição nos pontos de teste\n",
    "        y_pred = X_test @ a_opt\n",
    "        preds.append(y_pred)\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECOMPOSIÇÃO DO ERRO\n",
    "    # -------------------------------\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    bias2 = np.mean((np.mean(preds, axis=0) - f_real) ** 2)\n",
    "    var = np.mean(np.var(preds, axis=0))\n",
    "    noise = noise_std ** 2\n",
    "\n",
    "    bias2_list.append(bias2)\n",
    "    var_list.append(var)\n",
    "    noise_list.append(noise)\n",
    "\n",
    "# -------------------------------\n",
    "# PLOTAGEM DOS RESULTADOS\n",
    "# -------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alpha_values, bias2_list, label='Viés²', linewidth=2)\n",
    "plt.plot(alpha_values, var_list, label='Variância', linewidth=2)\n",
    "plt.plot(alpha_values, np.array(bias2_list) + np.array(var_list) + noise_list, \n",
    "         label='Erro Total', linewidth=2, color='black')\n",
    "plt.xlabel('Alpha (controle de complexidade)')\n",
    "plt.ylabel('Erro Médio')\n",
    "plt.title('Decomposição do Erro com Restrições Soft nos Coeficientes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experimento de Decomposição do Erro com Restrições Hard nos Coeficientes Polinomiais\n",
    "\n",
    "Este script simula o comportamento do erro de generalização de um modelo de regressão polinomial\n",
    "sob diferentes níveis de complexidade, controlados por um parâmetro de regularização alpha.\n",
    "\n",
    "A complexidade do modelo é limitada por restrições explícitas (hard constraints) impostas sobre\n",
    "os coeficientes do polinômio, de modo que |a_k| <= M * alpha^k.\n",
    "\n",
    "O experimento estima a decomposição do erro médio quadrático esperado (EMQ) em viés², variância\n",
    "e ruído, conforme alpha varia.\n",
    "\n",
    "Autor: [Seu Nome]\n",
    "Data: [Data]\n",
    "Licença: MIT\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, Bounds\n",
    "\n",
    "def f_true(x):\n",
    "    \"\"\"\n",
    "    Função alvo verdadeira a ser aproximada.\n",
    "\n",
    "    f(x) = 2x + cos(4πx)\n",
    "\n",
    "    Parâmetros:\n",
    "        x (array): entrada escalar ou vetorial\n",
    "\n",
    "    Retorna:\n",
    "        array: saída correspondente de f(x)\n",
    "    \"\"\"\n",
    "    return 2 * x + np.cos(4 * np.pi * x)\n",
    "\n",
    "def poly_basis(x, degree):\n",
    "    \"\"\"\n",
    "    Gera a matriz de design para uma base polinomial de grau especificado.\n",
    "\n",
    "    Parâmetros:\n",
    "        x (array): vetor de entradas\n",
    "        degree (int): grau máximo do polinômio\n",
    "\n",
    "    Retorna:\n",
    "        array: matriz de características (n x (degree+1))\n",
    "    \"\"\"\n",
    "    return np.vstack([x**k for k in range(degree + 1)]).T\n",
    "\n",
    "# ---------- Parâmetros do experimento ----------\n",
    "\n",
    "np.random.seed(42)            # Reprodutibilidade\n",
    "n_samples = 25                # Número de pontos de treino por dataset\n",
    "n_datasets = 100              # Número de repetições para média/variância\n",
    "n_test_points = 20            # Pontos para avaliação\n",
    "noise_std = 0.5               # Desvio padrão do ruído aditivo\n",
    "M = 1.0e3                     # Constante multiplicativa da restrição\n",
    "degree = 71                  # Grau máximo do polinômio\n",
    "alpha_values = np.linspace(0.2, 1.0, 51)  # Variação do parâmetro de regularização\n",
    "\n",
    "# Pontos de teste (fixos) para avaliação\n",
    "x_test_points = np.random.rand(n_test_points)\n",
    "X_test = poly_basis(x_test_points, degree)\n",
    "f_real = f_true(x_test_points)\n",
    "\n",
    "# ---------- Armazenamento dos resultados ----------\n",
    "bias2_list = []\n",
    "var_list = []\n",
    "noise_list = []\n",
    "\n",
    "# ---------- Loop sobre diferentes valores de alpha ----------\n",
    "a_init = np.zeros(degree + 1)  # Inicialização dos coeficientes\n",
    "\n",
    "for i, alpha in enumerate(alpha_values):\n",
    "    print(f\"Executando {i+1}/{len(alpha_values)}: alpha = {alpha:.3f}\")\n",
    "    preds = []\n",
    "\n",
    "    for _ in range(n_datasets):\n",
    "        # Geração de dados sintéticos com ruído\n",
    "        X_raw = np.linspace(0, 1, n_samples)\n",
    "        y = f_true(X_raw) + np.random.normal(0, noise_std, n_samples)\n",
    "        X_design = poly_basis(X_raw, degree)\n",
    "\n",
    "        # Definição das restrições hard: |a_k| <= M * alpha^k\n",
    "        lower_bounds = [-M * alpha**k for k in range(degree + 1)]\n",
    "        upper_bounds = [ M * alpha**k for k in range(degree + 1)]\n",
    "        bounds = Bounds(lower_bounds, upper_bounds)\n",
    "\n",
    "        # Minimização do erro quadrático com restrições\n",
    "        res = minimize(\n",
    "            lambda a: np.mean((y - X_design @ a) ** 2),\n",
    "            x0=a_init,\n",
    "            bounds=bounds\n",
    "        )\n",
    "\n",
    "        a_opt = res.x\n",
    "        a_init = a_opt  # Atualiza o ponto inicial para próxima execução\n",
    "        y_pred = X_test @ a_opt\n",
    "        preds.append(y_pred)\n",
    "\n",
    "    # Conversão para array e cálculo da decomposição do erro\n",
    "    preds = np.array(preds)\n",
    "    bias2 = np.mean((np.mean(preds, axis=0) - f_real) ** 2)\n",
    "    var = np.mean(np.var(preds, axis=0))\n",
    "    noise = noise_std ** 2\n",
    "\n",
    "    bias2_list.append(bias2)\n",
    "    var_list.append(var)\n",
    "    noise_list.append(noise)\n",
    "\n",
    "# ---------- Visualização ----------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alpha_values, bias2_list, label='Viés²')\n",
    "plt.plot(alpha_values, var_list, label='Variância')\n",
    "plt.plot(alpha_values, np.array(bias2_list) + np.array(var_list) + noise_list, label='Erro Total')\n",
    "plt.xlabel('Alpha (Parâmetro de Regularização)')\n",
    "plt.ylabel('Erro Médio')\n",
    "plt.title('Decomposição do Erro com Restrições Hard nos Coeficientes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
